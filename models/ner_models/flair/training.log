2022-11-23 13:42:19,164 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,166 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.25, inplace=False)
        (encoder): Embedding(275, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=275, bias=True)
      )
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.25, inplace=False)
        (encoder): Embedding(275, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=275, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)
  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=47, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-11-23 13:42:19,167 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,168 Corpus: "Corpus: 3200 train + 401 dev + 401 test sentences"
2022-11-23 13:42:19,169 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,170 Parameters:
2022-11-23 13:42:19,171  - learning_rate: "0.100000"
2022-11-23 13:42:19,172  - mini_batch_size: "32"
2022-11-23 13:42:19,173  - patience: "3"
2022-11-23 13:42:19,174  - anneal_factor: "0.5"
2022-11-23 13:42:19,175  - max_epochs: "10"
2022-11-23 13:42:19,176  - shuffle: "True"
2022-11-23 13:42:19,177  - train_with_dev: "False"
2022-11-23 13:42:19,178  - batch_growth_annealing: "False"
2022-11-23 13:42:19,179 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,179 Model training base path: "models\ner_models\flair"
2022-11-23 13:42:19,180 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,181 Device: cuda:0
2022-11-23 13:42:19,182 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,183 Embeddings storage mode: gpu
2022-11-23 13:42:19,184 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:19,997 epoch 1 - iter 10/100 - loss 3.57767052 - samples/sec: 394.45 - lr: 0.100000
2022-11-23 13:42:20,766 epoch 1 - iter 20/100 - loss 3.17685245 - samples/sec: 417.06 - lr: 0.100000
2022-11-23 13:42:21,516 epoch 1 - iter 30/100 - loss 2.93616282 - samples/sec: 427.33 - lr: 0.100000
2022-11-23 13:42:22,245 epoch 1 - iter 40/100 - loss 2.75386235 - samples/sec: 440.39 - lr: 0.100000
2022-11-23 13:42:22,961 epoch 1 - iter 50/100 - loss 2.63307402 - samples/sec: 447.84 - lr: 0.100000
2022-11-23 13:42:23,809 epoch 1 - iter 60/100 - loss 2.54009661 - samples/sec: 378.25 - lr: 0.100000
2022-11-23 13:42:24,537 epoch 1 - iter 70/100 - loss 2.42750138 - samples/sec: 440.76 - lr: 0.100000
2022-11-23 13:42:25,269 epoch 1 - iter 80/100 - loss 2.33842356 - samples/sec: 438.96 - lr: 0.100000
2022-11-23 13:42:26,002 epoch 1 - iter 90/100 - loss 2.25260952 - samples/sec: 438.36 - lr: 0.100000
2022-11-23 13:42:26,726 epoch 1 - iter 100/100 - loss 2.18480350 - samples/sec: 443.82 - lr: 0.100000
2022-11-23 13:42:26,727 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:26,727 EPOCH 1 done: loss 2.1848 - lr 0.100000
2022-11-23 13:42:27,809 Evaluating as a multi-label problem: False
2022-11-23 13:42:27,822 DEV : loss 1.2472093105316162 - f1-score (micro avg)  0.6347
2022-11-23 13:42:27,830 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:27,832 saving best model
2022-11-23 13:42:28,530 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:28,763 epoch 2 - iter 10/100 - loss 1.43692249 - samples/sec: 1397.40 - lr: 0.100000
2022-11-23 13:42:29,008 epoch 2 - iter 20/100 - loss 1.37321242 - samples/sec: 1316.87 - lr: 0.100000
2022-11-23 13:42:29,236 epoch 2 - iter 30/100 - loss 1.34296771 - samples/sec: 1422.22 - lr: 0.100000
2022-11-23 13:42:29,472 epoch 2 - iter 40/100 - loss 1.35099978 - samples/sec: 1367.53 - lr: 0.100000
2022-11-23 13:42:29,701 epoch 2 - iter 50/100 - loss 1.33625601 - samples/sec: 1403.50 - lr: 0.100000
2022-11-23 13:42:29,945 epoch 2 - iter 60/100 - loss 1.32141391 - samples/sec: 1322.32 - lr: 0.100000
2022-11-23 13:42:30,185 epoch 2 - iter 70/100 - loss 1.30116132 - samples/sec: 1350.22 - lr: 0.100000
2022-11-23 13:42:30,417 epoch 2 - iter 80/100 - loss 1.29030359 - samples/sec: 1397.26 - lr: 0.100000
2022-11-23 13:42:30,643 epoch 2 - iter 90/100 - loss 1.27149652 - samples/sec: 1441.43 - lr: 0.100000
2022-11-23 13:42:30,879 epoch 2 - iter 100/100 - loss 1.25944806 - samples/sec: 1367.52 - lr: 0.100000
2022-11-23 13:42:30,880 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:30,881 EPOCH 2 done: loss 1.2594 - lr 0.100000
2022-11-23 13:42:31,316 Evaluating as a multi-label problem: False
2022-11-23 13:42:31,329 DEV : loss 0.8964381814002991 - f1-score (micro avg)  0.7031
2022-11-23 13:42:31,337 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:31,338 saving best model
2022-11-23 13:42:32,056 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:32,291 epoch 3 - iter 10/100 - loss 1.01690784 - samples/sec: 1380.80 - lr: 0.100000
2022-11-23 13:42:32,529 epoch 3 - iter 20/100 - loss 1.07365253 - samples/sec: 1362.13 - lr: 0.100000
2022-11-23 13:42:32,766 epoch 3 - iter 30/100 - loss 1.08271915 - samples/sec: 1361.60 - lr: 0.100000
2022-11-23 13:42:32,993 epoch 3 - iter 40/100 - loss 1.05695919 - samples/sec: 1422.57 - lr: 0.100000
2022-11-23 13:42:33,232 epoch 3 - iter 50/100 - loss 1.05866040 - samples/sec: 1350.06 - lr: 0.100000
2022-11-23 13:42:33,461 epoch 3 - iter 60/100 - loss 1.04329547 - samples/sec: 1403.36 - lr: 0.100000
2022-11-23 13:42:33,699 epoch 3 - iter 70/100 - loss 1.03221356 - samples/sec: 1355.85 - lr: 0.100000
2022-11-23 13:42:33,940 epoch 3 - iter 80/100 - loss 1.02628808 - samples/sec: 1338.78 - lr: 0.100000
2022-11-23 13:42:34,183 epoch 3 - iter 90/100 - loss 1.01391856 - samples/sec: 1327.50 - lr: 0.100000
2022-11-23 13:42:34,415 epoch 3 - iter 100/100 - loss 0.99847857 - samples/sec: 1391.15 - lr: 0.100000
2022-11-23 13:42:34,417 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:34,418 EPOCH 3 done: loss 0.9985 - lr 0.100000
2022-11-23 13:42:34,855 Evaluating as a multi-label problem: False
2022-11-23 13:42:34,867 DEV : loss 0.7291697859764099 - f1-score (micro avg)  0.7483
2022-11-23 13:42:34,875 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:34,877 saving best model
2022-11-23 13:42:35,584 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:35,817 epoch 4 - iter 10/100 - loss 0.96283753 - samples/sec: 1409.70 - lr: 0.100000
2022-11-23 13:42:36,068 epoch 4 - iter 20/100 - loss 0.97040872 - samples/sec: 1292.85 - lr: 0.100000
2022-11-23 13:42:36,327 epoch 4 - iter 30/100 - loss 0.94653485 - samples/sec: 1249.95 - lr: 0.100000
2022-11-23 13:42:36,555 epoch 4 - iter 40/100 - loss 0.92465933 - samples/sec: 1409.69 - lr: 0.100000
2022-11-23 13:42:36,786 epoch 4 - iter 50/100 - loss 0.89689591 - samples/sec: 1403.52 - lr: 0.100000
2022-11-23 13:42:37,018 epoch 4 - iter 60/100 - loss 0.88834573 - samples/sec: 1391.30 - lr: 0.100000
2022-11-23 13:42:37,260 epoch 4 - iter 70/100 - loss 0.88714399 - samples/sec: 1344.54 - lr: 0.100000
2022-11-23 13:42:37,494 epoch 4 - iter 80/100 - loss 0.87960383 - samples/sec: 1373.41 - lr: 0.100000
2022-11-23 13:42:37,722 epoch 4 - iter 90/100 - loss 0.87123885 - samples/sec: 1409.69 - lr: 0.100000
2022-11-23 13:42:37,957 epoch 4 - iter 100/100 - loss 0.86271531 - samples/sec: 1373.40 - lr: 0.100000
2022-11-23 13:42:37,959 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:37,960 EPOCH 4 done: loss 0.8627 - lr 0.100000
2022-11-23 13:42:38,393 Evaluating as a multi-label problem: False
2022-11-23 13:42:38,406 DEV : loss 0.6760690212249756 - f1-score (micro avg)  0.769
2022-11-23 13:42:38,414 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:38,416 saving best model
2022-11-23 13:42:39,120 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:39,348 epoch 5 - iter 10/100 - loss 0.76627534 - samples/sec: 1428.57 - lr: 0.100000
2022-11-23 13:42:39,596 epoch 5 - iter 20/100 - loss 0.78489846 - samples/sec: 1300.82 - lr: 0.100000
2022-11-23 13:42:39,838 epoch 5 - iter 30/100 - loss 0.79016919 - samples/sec: 1333.33 - lr: 0.100000
2022-11-23 13:42:40,081 epoch 5 - iter 40/100 - loss 0.79636929 - samples/sec: 1322.32 - lr: 0.100000
2022-11-23 13:42:40,315 epoch 5 - iter 50/100 - loss 0.78293260 - samples/sec: 1373.39 - lr: 0.100000
2022-11-23 13:42:40,555 epoch 5 - iter 60/100 - loss 0.78318672 - samples/sec: 1338.93 - lr: 0.100000
2022-11-23 13:42:40,801 epoch 5 - iter 70/100 - loss 0.77112929 - samples/sec: 1311.48 - lr: 0.100000
2022-11-23 13:42:41,030 epoch 5 - iter 80/100 - loss 0.76861754 - samples/sec: 1409.70 - lr: 0.100000
2022-11-23 13:42:41,266 epoch 5 - iter 90/100 - loss 0.77178433 - samples/sec: 1373.39 - lr: 0.100000
2022-11-23 13:42:41,499 epoch 5 - iter 100/100 - loss 0.76717575 - samples/sec: 1391.32 - lr: 0.100000
2022-11-23 13:42:41,501 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:41,502 EPOCH 5 done: loss 0.7672 - lr 0.100000
2022-11-23 13:42:41,947 Evaluating as a multi-label problem: False
2022-11-23 13:42:41,959 DEV : loss 0.6060569286346436 - f1-score (micro avg)  0.7787
2022-11-23 13:42:41,968 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:41,970 saving best model
2022-11-23 13:42:42,685 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:42,917 epoch 6 - iter 10/100 - loss 0.70583337 - samples/sec: 1403.53 - lr: 0.100000
2022-11-23 13:42:43,148 epoch 6 - iter 20/100 - loss 0.75519577 - samples/sec: 1403.52 - lr: 0.100000
2022-11-23 13:42:43,389 epoch 6 - iter 30/100 - loss 0.74832640 - samples/sec: 1333.33 - lr: 0.100000
2022-11-23 13:42:43,635 epoch 6 - iter 40/100 - loss 0.73161762 - samples/sec: 1311.48 - lr: 0.100000
2022-11-23 13:42:43,875 epoch 6 - iter 50/100 - loss 0.71630152 - samples/sec: 1338.92 - lr: 0.100000
2022-11-23 13:42:44,104 epoch 6 - iter 60/100 - loss 0.71072069 - samples/sec: 1415.94 - lr: 0.100000
2022-11-23 13:42:44,341 epoch 6 - iter 70/100 - loss 0.70566698 - samples/sec: 1361.71 - lr: 0.100000
2022-11-23 13:42:44,576 epoch 6 - iter 80/100 - loss 0.70641259 - samples/sec: 1367.52 - lr: 0.100000
2022-11-23 13:42:44,815 epoch 6 - iter 90/100 - loss 0.71409769 - samples/sec: 1350.22 - lr: 0.100000
2022-11-23 13:42:45,043 epoch 6 - iter 100/100 - loss 0.70985446 - samples/sec: 1409.70 - lr: 0.100000
2022-11-23 13:42:45,045 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:45,046 EPOCH 6 done: loss 0.7099 - lr 0.100000
2022-11-23 13:42:45,486 Evaluating as a multi-label problem: False
2022-11-23 13:42:45,499 DEV : loss 0.6382891535758972 - f1-score (micro avg)  0.7716
2022-11-23 13:42:45,507 BAD EPOCHS (no improvement): 1
2022-11-23 13:42:45,509 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:45,745 epoch 7 - iter 10/100 - loss 0.61624884 - samples/sec: 1373.39 - lr: 0.100000
2022-11-23 13:42:45,980 epoch 7 - iter 20/100 - loss 0.64597210 - samples/sec: 1367.52 - lr: 0.100000
2022-11-23 13:42:46,213 epoch 7 - iter 30/100 - loss 0.61691749 - samples/sec: 1385.29 - lr: 0.100000
2022-11-23 13:42:46,448 epoch 7 - iter 40/100 - loss 0.63591151 - samples/sec: 1373.40 - lr: 0.100000
2022-11-23 13:42:46,673 epoch 7 - iter 50/100 - loss 0.64754442 - samples/sec: 1434.98 - lr: 0.100000
2022-11-23 13:42:46,915 epoch 7 - iter 60/100 - loss 0.65196755 - samples/sec: 1327.81 - lr: 0.100000
2022-11-23 13:42:47,148 epoch 7 - iter 70/100 - loss 0.64992952 - samples/sec: 1379.31 - lr: 0.100000
2022-11-23 13:42:47,381 epoch 7 - iter 80/100 - loss 0.64862262 - samples/sec: 1379.31 - lr: 0.100000
2022-11-23 13:42:47,611 epoch 7 - iter 90/100 - loss 0.65299037 - samples/sec: 1422.09 - lr: 0.100000
2022-11-23 13:42:47,851 epoch 7 - iter 100/100 - loss 0.64628886 - samples/sec: 1343.32 - lr: 0.100000
2022-11-23 13:42:47,853 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:47,853 EPOCH 7 done: loss 0.6463 - lr 0.100000
2022-11-23 13:42:48,447 Evaluating as a multi-label problem: False
2022-11-23 13:42:48,459 DEV : loss 0.6019043326377869 - f1-score (micro avg)  0.78
2022-11-23 13:42:48,467 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:48,469 saving best model
2022-11-23 13:42:49,180 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:49,418 epoch 8 - iter 10/100 - loss 0.61074184 - samples/sec: 1361.76 - lr: 0.100000
2022-11-23 13:42:49,649 epoch 8 - iter 20/100 - loss 0.63358930 - samples/sec: 1391.32 - lr: 0.100000
2022-11-23 13:42:49,876 epoch 8 - iter 30/100 - loss 0.63715997 - samples/sec: 1415.95 - lr: 0.100000
2022-11-23 13:42:50,119 epoch 8 - iter 40/100 - loss 0.61378976 - samples/sec: 1324.63 - lr: 0.100000
2022-11-23 13:42:50,369 epoch 8 - iter 50/100 - loss 0.62808950 - samples/sec: 1297.53 - lr: 0.100000
2022-11-23 13:42:50,602 epoch 8 - iter 60/100 - loss 0.62822052 - samples/sec: 1385.29 - lr: 0.100000
2022-11-23 13:42:50,847 epoch 8 - iter 70/100 - loss 0.61723402 - samples/sec: 1317.92 - lr: 0.100000
2022-11-23 13:42:51,103 epoch 8 - iter 80/100 - loss 0.61103654 - samples/sec: 1259.97 - lr: 0.100000
2022-11-23 13:42:51,338 epoch 8 - iter 90/100 - loss 0.61181627 - samples/sec: 1379.33 - lr: 0.100000
2022-11-23 13:42:51,585 epoch 8 - iter 100/100 - loss 0.61656977 - samples/sec: 1311.50 - lr: 0.100000
2022-11-23 13:42:51,586 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:51,588 EPOCH 8 done: loss 0.6166 - lr 0.100000
2022-11-23 13:42:52,030 Evaluating as a multi-label problem: False
2022-11-23 13:42:52,043 DEV : loss 0.5799474716186523 - f1-score (micro avg)  0.7824
2022-11-23 13:42:52,050 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:52,052 saving best model
2022-11-23 13:42:52,762 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:52,998 epoch 9 - iter 10/100 - loss 0.58800616 - samples/sec: 1381.63 - lr: 0.100000
2022-11-23 13:42:53,256 epoch 9 - iter 20/100 - loss 0.59572057 - samples/sec: 1249.99 - lr: 0.100000
2022-11-23 13:42:53,486 epoch 9 - iter 30/100 - loss 0.60261734 - samples/sec: 1409.87 - lr: 0.100000
2022-11-23 13:42:53,732 epoch 9 - iter 40/100 - loss 0.59319719 - samples/sec: 1315.78 - lr: 0.100000
2022-11-23 13:42:53,968 epoch 9 - iter 50/100 - loss 0.58632868 - samples/sec: 1372.56 - lr: 0.100000
2022-11-23 13:42:54,216 epoch 9 - iter 60/100 - loss 0.58270096 - samples/sec: 1301.32 - lr: 0.100000
2022-11-23 13:42:54,461 epoch 9 - iter 70/100 - loss 0.57930092 - samples/sec: 1327.76 - lr: 0.100000
2022-11-23 13:42:54,698 epoch 9 - iter 80/100 - loss 0.58536733 - samples/sec: 1362.11 - lr: 0.100000
2022-11-23 13:42:54,930 epoch 9 - iter 90/100 - loss 0.58575304 - samples/sec: 1397.32 - lr: 0.100000
2022-11-23 13:42:55,166 epoch 9 - iter 100/100 - loss 0.58562331 - samples/sec: 1373.53 - lr: 0.100000
2022-11-23 13:42:55,168 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:55,169 EPOCH 9 done: loss 0.5856 - lr 0.100000
2022-11-23 13:42:55,618 Evaluating as a multi-label problem: False
2022-11-23 13:42:55,630 DEV : loss 0.5421388149261475 - f1-score (micro avg)  0.8009
2022-11-23 13:42:55,638 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:55,640 saving best model
2022-11-23 13:42:56,354 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:56,601 epoch 10 - iter 10/100 - loss 0.57466440 - samples/sec: 1316.80 - lr: 0.100000
2022-11-23 13:42:56,830 epoch 10 - iter 20/100 - loss 0.58684094 - samples/sec: 1421.82 - lr: 0.100000
2022-11-23 13:42:57,070 epoch 10 - iter 30/100 - loss 0.56883227 - samples/sec: 1350.36 - lr: 0.100000
2022-11-23 13:42:57,319 epoch 10 - iter 40/100 - loss 0.55401358 - samples/sec: 1306.18 - lr: 0.100000
2022-11-23 13:42:57,560 epoch 10 - iter 50/100 - loss 0.54733924 - samples/sec: 1349.59 - lr: 0.100000
2022-11-23 13:42:57,812 epoch 10 - iter 60/100 - loss 0.55085324 - samples/sec: 1285.07 - lr: 0.100000
2022-11-23 13:42:58,051 epoch 10 - iter 70/100 - loss 0.55724558 - samples/sec: 1350.88 - lr: 0.100000
2022-11-23 13:42:58,302 epoch 10 - iter 80/100 - loss 0.55054992 - samples/sec: 1285.15 - lr: 0.100000
2022-11-23 13:42:58,547 epoch 10 - iter 90/100 - loss 0.55533422 - samples/sec: 1311.73 - lr: 0.100000
2022-11-23 13:42:58,781 epoch 10 - iter 100/100 - loss 0.55548531 - samples/sec: 1379.05 - lr: 0.100000
2022-11-23 13:42:58,783 ----------------------------------------------------------------------------------------------------
2022-11-23 13:42:58,784 EPOCH 10 done: loss 0.5555 - lr 0.100000
2022-11-23 13:42:59,224 Evaluating as a multi-label problem: False
2022-11-23 13:42:59,236 DEV : loss 0.5560851693153381 - f1-score (micro avg)  0.8116
2022-11-23 13:42:59,243 BAD EPOCHS (no improvement): 0
2022-11-23 13:42:59,245 saving best model
2022-11-23 13:43:00,707 ----------------------------------------------------------------------------------------------------
2022-11-23 13:43:00,709 loading file models\ner_models\flair\best-model.pt
2022-11-23 13:43:01,113 SequenceTagger predicts: Dictionary with 47 tags: O, S-Item, B-Item, E-Item, I-Item, S-Activity, B-Activity, E-Activity, I-Activity, S-Observation, B-Observation, E-Observation, I-Observation, S-Location, B-Location, E-Location, I-Location, S-Consumable, B-Consumable, E-Consumable, I-Consumable, S-Agent, B-Agent, E-Agent, I-Agent, S-Specifier, B-Specifier, E-Specifier, I-Specifier, S-Cardinality, B-Cardinality, E-Cardinality, I-Cardinality, S-Attribute, B-Attribute, E-Attribute, I-Attribute, S-Time, B-Time, E-Time, I-Time, S-Event, B-Event, E-Event, I-Event, <START>, <STOP>
2022-11-23 13:43:02,369 Evaluating as a multi-label problem: False
2022-11-23 13:43:02,381 0.7524	0.8009	0.7759	0.6451
2022-11-23 13:43:02,383 
Results:
- F-score (micro) 0.7759
- F-score (macro) 0.78
- Accuracy 0.6451

By class:
              precision    recall  f1-score   support

        Item     0.6919    0.7828    0.7346       548
 Observation     0.7445    0.7578    0.7511       223
    Activity     0.8744    0.8704    0.8724       216
    Location     0.8014    0.8014    0.8014       141
  Consumable     0.8444    0.8085    0.8261        47
       Agent     0.8095    1.0000    0.8947        34
 Cardinality     0.8500    0.9444    0.8947        18
        Time     1.0000    0.9474    0.9730        19
   Attribute     0.1429    0.1429    0.1429        14
   Specifier     0.9091    0.9091    0.9091        11

   micro avg     0.7524    0.8009    0.7759      1271
   macro avg     0.7668    0.7965    0.7800      1271
weighted avg     0.7558    0.8009    0.7768      1271

2022-11-23 13:43:02,383 ----------------------------------------------------------------------------------------------------
