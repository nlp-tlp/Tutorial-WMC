2022-11-29 19:55:19,593 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:19,594 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.25, inplace=False)
        (encoder): Embedding(275, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=275, bias=True)
      )
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.25, inplace=False)
        (encoder): Embedding(275, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=275, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)
  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=15, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-11-29 19:55:19,595 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:19,597 Corpus: "Corpus: 3200 train + 401 dev + 401 test sentences"
2022-11-29 19:55:19,597 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:19,599 Parameters:
2022-11-29 19:55:19,600  - learning_rate: "0.100000"
2022-11-29 19:55:19,601  - mini_batch_size: "32"
2022-11-29 19:55:19,602  - patience: "3"
2022-11-29 19:55:19,603  - anneal_factor: "0.5"
2022-11-29 19:55:19,604  - max_epochs: "10"
2022-11-29 19:55:19,605  - shuffle: "True"
2022-11-29 19:55:19,606  - train_with_dev: "False"
2022-11-29 19:55:19,607  - batch_growth_annealing: "False"
2022-11-29 19:55:19,609 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:19,610 Model training base path: "models\ner_models\flair"
2022-11-29 19:55:19,611 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:19,612 Device: cuda:0
2022-11-29 19:55:19,613 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:19,615 Embeddings storage mode: gpu
2022-11-29 19:55:19,616 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:20,794 epoch 1 - iter 10/100 - loss 2.51444360 - samples/sec: 271.88 - lr: 0.100000
2022-11-29 19:55:21,564 epoch 1 - iter 20/100 - loss 2.26125464 - samples/sec: 416.67 - lr: 0.100000
2022-11-29 19:55:22,363 epoch 1 - iter 30/100 - loss 2.07498067 - samples/sec: 401.50 - lr: 0.100000
2022-11-29 19:55:23,306 epoch 1 - iter 40/100 - loss 1.93443117 - samples/sec: 340.06 - lr: 0.100000
2022-11-29 19:55:24,072 epoch 1 - iter 50/100 - loss 1.83384382 - samples/sec: 418.85 - lr: 0.100000
2022-11-29 19:55:24,832 epoch 1 - iter 60/100 - loss 1.74987443 - samples/sec: 422.16 - lr: 0.100000
2022-11-29 19:55:25,602 epoch 1 - iter 70/100 - loss 1.65976205 - samples/sec: 417.21 - lr: 0.100000
2022-11-29 19:55:26,397 epoch 1 - iter 80/100 - loss 1.58696204 - samples/sec: 403.53 - lr: 0.100000
2022-11-29 19:55:27,195 epoch 1 - iter 90/100 - loss 1.52321554 - samples/sec: 402.52 - lr: 0.100000
2022-11-29 19:55:27,983 epoch 1 - iter 100/100 - loss 1.46963711 - samples/sec: 407.12 - lr: 0.100000
2022-11-29 19:55:27,984 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:27,985 EPOCH 1 done: loss 1.4696 - lr 0.100000
2022-11-29 19:55:29,146 Evaluating as a multi-label problem: False
2022-11-29 19:55:29,162 DEV : loss 0.743816614151001 - f1-score (micro avg)  0.6684
2022-11-29 19:55:29,170 BAD EPOCHS (no improvement): 0
2022-11-29 19:55:29,172 saving best model
2022-11-29 19:55:29,960 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:30,227 epoch 2 - iter 10/100 - loss 0.93122098 - samples/sec: 1212.12 - lr: 0.100000
2022-11-29 19:55:30,472 epoch 2 - iter 20/100 - loss 0.93700673 - samples/sec: 1311.46 - lr: 0.100000
2022-11-29 19:55:30,716 epoch 2 - iter 30/100 - loss 0.92589947 - samples/sec: 1322.31 - lr: 0.100000
2022-11-29 19:55:30,964 epoch 2 - iter 40/100 - loss 0.91140916 - samples/sec: 1300.83 - lr: 0.100000
2022-11-29 19:55:31,218 epoch 2 - iter 50/100 - loss 0.90092413 - samples/sec: 1269.84 - lr: 0.100000
2022-11-29 19:55:31,469 epoch 2 - iter 60/100 - loss 0.88857491 - samples/sec: 1295.53 - lr: 0.100000
2022-11-29 19:55:31,718 epoch 2 - iter 70/100 - loss 0.88186254 - samples/sec: 1300.81 - lr: 0.100000
2022-11-29 19:55:31,978 epoch 2 - iter 80/100 - loss 0.86919368 - samples/sec: 1240.31 - lr: 0.100000
2022-11-29 19:55:32,230 epoch 2 - iter 90/100 - loss 0.86008132 - samples/sec: 1274.91 - lr: 0.100000
2022-11-29 19:55:32,469 epoch 2 - iter 100/100 - loss 0.84783343 - samples/sec: 1355.94 - lr: 0.100000
2022-11-29 19:55:32,471 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:32,472 EPOCH 2 done: loss 0.8478 - lr 0.100000
2022-11-29 19:55:32,906 Evaluating as a multi-label problem: False
2022-11-29 19:55:32,918 DEV : loss 0.5499727725982666 - f1-score (micro avg)  0.7507
2022-11-29 19:55:32,925 BAD EPOCHS (no improvement): 0
2022-11-29 19:55:32,927 saving best model
2022-11-29 19:55:33,696 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:33,939 epoch 3 - iter 10/100 - loss 0.74651710 - samples/sec: 1338.91 - lr: 0.100000
2022-11-29 19:55:34,185 epoch 3 - iter 20/100 - loss 0.72825161 - samples/sec: 1311.48 - lr: 0.100000
2022-11-29 19:55:34,437 epoch 3 - iter 30/100 - loss 0.72226545 - samples/sec: 1280.02 - lr: 0.100000
2022-11-29 19:55:34,684 epoch 3 - iter 40/100 - loss 0.71087911 - samples/sec: 1311.47 - lr: 0.100000
2022-11-29 19:55:34,928 epoch 3 - iter 50/100 - loss 0.71147087 - samples/sec: 1322.32 - lr: 0.100000
2022-11-29 19:55:35,170 epoch 3 - iter 60/100 - loss 0.70753659 - samples/sec: 1338.93 - lr: 0.100000
2022-11-29 19:55:35,418 epoch 3 - iter 70/100 - loss 0.70232310 - samples/sec: 1300.81 - lr: 0.100000
2022-11-29 19:55:35,677 epoch 3 - iter 80/100 - loss 0.69187476 - samples/sec: 1245.14 - lr: 0.100000
2022-11-29 19:55:35,927 epoch 3 - iter 90/100 - loss 0.69092892 - samples/sec: 1290.33 - lr: 0.100000
2022-11-29 19:55:36,165 epoch 3 - iter 100/100 - loss 0.69021075 - samples/sec: 1361.70 - lr: 0.100000
2022-11-29 19:55:36,166 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:36,167 EPOCH 3 done: loss 0.6902 - lr 0.100000
2022-11-29 19:55:36,608 Evaluating as a multi-label problem: False
2022-11-29 19:55:36,619 DEV : loss 0.5182793736457825 - f1-score (micro avg)  0.7469
2022-11-29 19:55:36,627 BAD EPOCHS (no improvement): 1
2022-11-29 19:55:36,628 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:36,877 epoch 4 - iter 10/100 - loss 0.55811226 - samples/sec: 1295.55 - lr: 0.100000
2022-11-29 19:55:37,123 epoch 4 - iter 20/100 - loss 0.59166121 - samples/sec: 1311.48 - lr: 0.100000
2022-11-29 19:55:37,384 epoch 4 - iter 30/100 - loss 0.60031438 - samples/sec: 1230.64 - lr: 0.100000
2022-11-29 19:55:37,652 epoch 4 - iter 40/100 - loss 0.60103191 - samples/sec: 1221.61 - lr: 0.100000
2022-11-29 19:55:37,899 epoch 4 - iter 50/100 - loss 0.60056311 - samples/sec: 1311.47 - lr: 0.100000
2022-11-29 19:55:38,157 epoch 4 - iter 60/100 - loss 0.59683237 - samples/sec: 1248.48 - lr: 0.100000
2022-11-29 19:55:38,430 epoch 4 - iter 70/100 - loss 0.59160524 - samples/sec: 1180.76 - lr: 0.100000
2022-11-29 19:55:38,714 epoch 4 - iter 80/100 - loss 0.58813251 - samples/sec: 1135.77 - lr: 0.100000
2022-11-29 19:55:39,030 epoch 4 - iter 90/100 - loss 0.58326348 - samples/sec: 1018.25 - lr: 0.100000
2022-11-29 19:55:39,318 epoch 4 - iter 100/100 - loss 0.58096572 - samples/sec: 1123.08 - lr: 0.100000
2022-11-29 19:55:39,320 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:39,321 EPOCH 4 done: loss 0.5810 - lr 0.100000
2022-11-29 19:55:39,782 Evaluating as a multi-label problem: False
2022-11-29 19:55:39,794 DEV : loss 0.4407889246940613 - f1-score (micro avg)  0.7854
2022-11-29 19:55:39,802 BAD EPOCHS (no improvement): 0
2022-11-29 19:55:39,804 saving best model
2022-11-29 19:55:40,596 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:40,878 epoch 5 - iter 10/100 - loss 0.56197289 - samples/sec: 1142.34 - lr: 0.100000
2022-11-29 19:55:41,139 epoch 5 - iter 20/100 - loss 0.53811764 - samples/sec: 1240.30 - lr: 0.100000
2022-11-29 19:55:41,397 epoch 5 - iter 30/100 - loss 0.54474518 - samples/sec: 1253.62 - lr: 0.100000
2022-11-29 19:55:41,655 epoch 5 - iter 40/100 - loss 0.55153870 - samples/sec: 1252.74 - lr: 0.100000
2022-11-29 19:55:41,904 epoch 5 - iter 50/100 - loss 0.55267311 - samples/sec: 1290.31 - lr: 0.100000
2022-11-29 19:55:42,160 epoch 5 - iter 60/100 - loss 0.54321808 - samples/sec: 1259.84 - lr: 0.100000
2022-11-29 19:55:42,420 epoch 5 - iter 70/100 - loss 0.53776303 - samples/sec: 1241.33 - lr: 0.100000
2022-11-29 19:55:42,676 epoch 5 - iter 80/100 - loss 0.53917517 - samples/sec: 1259.84 - lr: 0.100000
2022-11-29 19:55:42,930 epoch 5 - iter 90/100 - loss 0.54249645 - samples/sec: 1269.81 - lr: 0.100000
2022-11-29 19:55:43,190 epoch 5 - iter 100/100 - loss 0.53252619 - samples/sec: 1244.40 - lr: 0.100000
2022-11-29 19:55:43,192 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:43,193 EPOCH 5 done: loss 0.5325 - lr 0.100000
2022-11-29 19:55:43,645 Evaluating as a multi-label problem: False
2022-11-29 19:55:43,657 DEV : loss 0.40568605065345764 - f1-score (micro avg)  0.8008
2022-11-29 19:55:43,664 BAD EPOCHS (no improvement): 0
2022-11-29 19:55:43,666 saving best model
2022-11-29 19:55:44,450 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:44,710 epoch 6 - iter 10/100 - loss 0.53370135 - samples/sec: 1240.31 - lr: 0.100000
2022-11-29 19:55:44,971 epoch 6 - iter 20/100 - loss 0.52620640 - samples/sec: 1235.53 - lr: 0.100000
2022-11-29 19:55:45,226 epoch 6 - iter 30/100 - loss 0.50857884 - samples/sec: 1269.84 - lr: 0.100000
2022-11-29 19:55:45,475 epoch 6 - iter 40/100 - loss 0.51512304 - samples/sec: 1300.80 - lr: 0.100000
2022-11-29 19:55:45,738 epoch 6 - iter 50/100 - loss 0.50988354 - samples/sec: 1222.70 - lr: 0.100000
2022-11-29 19:55:46,009 epoch 6 - iter 60/100 - loss 0.50078065 - samples/sec: 1188.89 - lr: 0.100000
2022-11-29 19:55:46,272 epoch 6 - iter 70/100 - loss 0.49147668 - samples/sec: 1235.51 - lr: 0.100000
2022-11-29 19:55:46,526 epoch 6 - iter 80/100 - loss 0.49512972 - samples/sec: 1266.58 - lr: 0.100000
2022-11-29 19:55:46,774 epoch 6 - iter 90/100 - loss 0.49726457 - samples/sec: 1295.55 - lr: 0.100000
2022-11-29 19:55:47,041 epoch 6 - iter 100/100 - loss 0.49195739 - samples/sec: 1205.56 - lr: 0.100000
2022-11-29 19:55:47,043 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:47,044 EPOCH 6 done: loss 0.4920 - lr 0.100000
2022-11-29 19:55:47,481 Evaluating as a multi-label problem: False
2022-11-29 19:55:47,492 DEV : loss 0.410269558429718 - f1-score (micro avg)  0.7988
2022-11-29 19:55:47,500 BAD EPOCHS (no improvement): 1
2022-11-29 19:55:47,502 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:47,750 epoch 7 - iter 10/100 - loss 0.46687846 - samples/sec: 1295.41 - lr: 0.100000
2022-11-29 19:55:48,003 epoch 7 - iter 20/100 - loss 0.49256551 - samples/sec: 1285.09 - lr: 0.100000
2022-11-29 19:55:48,257 epoch 7 - iter 30/100 - loss 0.48660147 - samples/sec: 1269.85 - lr: 0.100000
2022-11-29 19:55:48,508 epoch 7 - iter 40/100 - loss 0.47807865 - samples/sec: 1285.07 - lr: 0.100000
2022-11-29 19:55:48,769 epoch 7 - iter 50/100 - loss 0.46595729 - samples/sec: 1259.41 - lr: 0.100000
2022-11-29 19:55:49,026 epoch 7 - iter 60/100 - loss 0.46114198 - samples/sec: 1253.73 - lr: 0.100000
2022-11-29 19:55:49,310 epoch 7 - iter 70/100 - loss 0.45048113 - samples/sec: 1132.92 - lr: 0.100000
2022-11-29 19:55:49,584 epoch 7 - iter 80/100 - loss 0.45121334 - samples/sec: 1180.54 - lr: 0.100000
2022-11-29 19:55:49,855 epoch 7 - iter 90/100 - loss 0.45056088 - samples/sec: 1189.15 - lr: 0.100000
2022-11-29 19:55:50,116 epoch 7 - iter 100/100 - loss 0.44944011 - samples/sec: 1233.24 - lr: 0.100000
2022-11-29 19:55:50,118 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:50,119 EPOCH 7 done: loss 0.4494 - lr 0.100000
2022-11-29 19:55:50,574 Evaluating as a multi-label problem: False
2022-11-29 19:55:50,583 DEV : loss 0.4015345871448517 - f1-score (micro avg)  0.8039
2022-11-29 19:55:50,591 BAD EPOCHS (no improvement): 0
2022-11-29 19:55:50,593 saving best model
2022-11-29 19:55:51,377 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:51,633 epoch 8 - iter 10/100 - loss 0.39979676 - samples/sec: 1264.81 - lr: 0.100000
2022-11-29 19:55:51,891 epoch 8 - iter 20/100 - loss 0.42294478 - samples/sec: 1255.60 - lr: 0.100000
2022-11-29 19:55:52,147 epoch 8 - iter 30/100 - loss 0.43561446 - samples/sec: 1256.72 - lr: 0.100000
2022-11-29 19:55:52,401 epoch 8 - iter 40/100 - loss 0.42958077 - samples/sec: 1269.11 - lr: 0.100000
2022-11-29 19:55:52,651 epoch 8 - iter 50/100 - loss 0.43644458 - samples/sec: 1296.15 - lr: 0.100000
2022-11-29 19:55:52,912 epoch 8 - iter 60/100 - loss 0.44022842 - samples/sec: 1235.50 - lr: 0.100000
2022-11-29 19:55:53,174 epoch 8 - iter 70/100 - loss 0.43387762 - samples/sec: 1246.46 - lr: 0.100000
2022-11-29 19:55:53,429 epoch 8 - iter 80/100 - loss 0.43344584 - samples/sec: 1264.25 - lr: 0.100000
2022-11-29 19:55:53,695 epoch 8 - iter 90/100 - loss 0.43213231 - samples/sec: 1211.55 - lr: 0.100000
2022-11-29 19:55:53,954 epoch 8 - iter 100/100 - loss 0.43290627 - samples/sec: 1245.12 - lr: 0.100000
2022-11-29 19:55:53,956 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:53,957 EPOCH 8 done: loss 0.4329 - lr 0.100000
2022-11-29 19:55:54,408 Evaluating as a multi-label problem: False
2022-11-29 19:55:54,418 DEV : loss 0.41782504320144653 - f1-score (micro avg)  0.7641
2022-11-29 19:55:54,426 BAD EPOCHS (no improvement): 1
2022-11-29 19:55:54,428 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:54,679 epoch 9 - iter 10/100 - loss 0.38809048 - samples/sec: 1285.14 - lr: 0.100000
2022-11-29 19:55:54,938 epoch 9 - iter 20/100 - loss 0.38429409 - samples/sec: 1256.56 - lr: 0.100000
2022-11-29 19:55:55,189 epoch 9 - iter 30/100 - loss 0.39951865 - samples/sec: 1281.77 - lr: 0.100000
2022-11-29 19:55:55,448 epoch 9 - iter 40/100 - loss 0.40274063 - samples/sec: 1245.02 - lr: 0.100000
2022-11-29 19:55:55,706 epoch 9 - iter 50/100 - loss 0.40411498 - samples/sec: 1258.99 - lr: 0.100000
2022-11-29 19:55:55,963 epoch 9 - iter 60/100 - loss 0.40716752 - samples/sec: 1254.85 - lr: 0.100000
2022-11-29 19:55:56,215 epoch 9 - iter 70/100 - loss 0.40607803 - samples/sec: 1280.01 - lr: 0.100000
2022-11-29 19:55:56,470 epoch 9 - iter 80/100 - loss 0.40395778 - samples/sec: 1261.20 - lr: 0.100000
2022-11-29 19:55:56,746 epoch 9 - iter 90/100 - loss 0.40295678 - samples/sec: 1163.38 - lr: 0.100000
2022-11-29 19:55:57,000 epoch 9 - iter 100/100 - loss 0.40353242 - samples/sec: 1270.32 - lr: 0.100000
2022-11-29 19:55:57,002 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:57,003 EPOCH 9 done: loss 0.4035 - lr 0.100000
2022-11-29 19:55:57,447 Evaluating as a multi-label problem: False
2022-11-29 19:55:57,459 DEV : loss 0.40029552578926086 - f1-score (micro avg)  0.7899
2022-11-29 19:55:57,468 BAD EPOCHS (no improvement): 2
2022-11-29 19:55:57,469 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:57,739 epoch 10 - iter 10/100 - loss 0.38553391 - samples/sec: 1196.01 - lr: 0.100000
2022-11-29 19:55:57,984 epoch 10 - iter 20/100 - loss 0.38512171 - samples/sec: 1322.31 - lr: 0.100000
2022-11-29 19:55:58,230 epoch 10 - iter 30/100 - loss 0.37342493 - samples/sec: 1316.88 - lr: 0.100000
2022-11-29 19:55:58,485 epoch 10 - iter 40/100 - loss 0.38000802 - samples/sec: 1264.83 - lr: 0.100000
2022-11-29 19:55:58,728 epoch 10 - iter 50/100 - loss 0.38083797 - samples/sec: 1338.91 - lr: 0.100000
2022-11-29 19:55:58,974 epoch 10 - iter 60/100 - loss 0.38513078 - samples/sec: 1316.08 - lr: 0.100000
2022-11-29 19:55:59,220 epoch 10 - iter 70/100 - loss 0.38870147 - samples/sec: 1311.48 - lr: 0.100000
2022-11-29 19:55:59,477 epoch 10 - iter 80/100 - loss 0.38746411 - samples/sec: 1264.54 - lr: 0.100000
2022-11-29 19:55:59,724 epoch 10 - iter 90/100 - loss 0.39006729 - samples/sec: 1316.87 - lr: 0.100000
2022-11-29 19:55:59,979 epoch 10 - iter 100/100 - loss 0.39083806 - samples/sec: 1264.82 - lr: 0.100000
2022-11-29 19:55:59,981 ----------------------------------------------------------------------------------------------------
2022-11-29 19:55:59,982 EPOCH 10 done: loss 0.3908 - lr 0.100000
2022-11-29 19:56:00,610 Evaluating as a multi-label problem: False
2022-11-29 19:56:00,621 DEV : loss 0.37994131445884705 - f1-score (micro avg)  0.8077
2022-11-29 19:56:00,629 BAD EPOCHS (no improvement): 0
2022-11-29 19:56:00,631 saving best model
2022-11-29 19:56:02,157 ----------------------------------------------------------------------------------------------------
2022-11-29 19:56:02,159 loading file models\ner_models\flair\best-model.pt
2022-11-29 19:56:02,668 SequenceTagger predicts: Dictionary with 15 tags: O, S-Item, B-Item, E-Item, I-Item, S-Activity, B-Activity, E-Activity, I-Activity, S-Observation, B-Observation, E-Observation, I-Observation, <START>, <STOP>
2022-11-29 19:56:04,074 Evaluating as a multi-label problem: False
2022-11-29 19:56:04,084 0.7956	0.7771	0.7863	0.6533
2022-11-29 19:56:04,086 
Results:
- F-score (micro) 0.7863
- F-score (macro) 0.8002
- Accuracy 0.6533

By class:
              precision    recall  f1-score   support

        Item     0.7638    0.7555    0.7596       548
 Observation     0.7725    0.7309    0.7512       223
    Activity     0.9005    0.8796    0.8899       216

   micro avg     0.7956    0.7771    0.7863       987
   macro avg     0.8123    0.7887    0.8002       987
weighted avg     0.7957    0.7771    0.7862       987

2022-11-29 19:56:04,087 ----------------------------------------------------------------------------------------------------
